{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base anomaly detection function\n",
    "\n",
    "### Detects anomalies in time series using S-H-ESD\n",
    "\n",
    "#### Input Data format\n",
    "\n",
    "detect_anoms <- function(data, k = 0.49, alpha = 0.05, num_obs_per_period = NULL,use_decomp = TRUE, use_esd = FALSE, one_tail = TRUE,upper_tail = TRUE, verbose = FALSE)\n",
    "                         \n",
    "* **Data** should be of type list where the first element should have the time stamps and second element - the actual data\n",
    "* k: Maximum number of anomalies that S-H-ESD will detect as a percentage of the data\n",
    "* alpha: The level of statistical significance with which to accept or reject anomalies\n",
    "* num_obs_per_period: Defines the number of observations in a single period, and used during seasonal decomposition\n",
    "* use_decomp: Use seasonal decomposition during anomaly detection\n",
    "* Total number of observations should be two times the **num_obs_per_period**, by which we get enough data to compute seasonality \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief intro about ESD:\n",
    "\n",
    "The generalized (extreme Studentized deviate) ESD test is used to detect one or more outliers in a univariate data set that follows an approximately normal distribution.\n",
    "\n",
    "The generalized ESD test is defined for the hypothesis:\n",
    "\n",
    "** H0:\tThere are no outliers in the data set**\n",
    "\n",
    "**Ha:\tThere are up to r outliers in the data set ** \n",
    "\n",
    "We test the null hypothesis that the data has no outliers vs. the alternative hypothesis that there are at most k outliers (for some user specified value of k).\n",
    "\n",
    "To test the data set S with n elements is we generate k test statistics G1, G2, …, Gk where each Gj statistic (Grubb's statistic) is defined as follows,\n",
    "\n",
    "<img src = \"https://i2.wp.com/www.real-statistics.com/wp-content/uploads/2014/12/image9116.png\">\n",
    "\n",
    "\n",
    "where tcrit is the critical value of the t distribution T(n−2) and the significance level is α/n. Thus the null hypothesis is rejected if G > Gcrit.\n",
    "\n",
    "two-tailed Grubbs’ statistic, defined as follows:\n",
    "                   \n",
    "                   S1 = S\n",
    "\n",
    " x̄j is the mean of Sj and sj is the standard deviation of Sj\n",
    " \n",
    " <img src=\"https://i0.wp.com/www.real-statistics.com/wp-content/uploads/2014/12/image9118.png\">\n",
    " \n",
    " Essentially you run k separate Grubbs’ tests, testing whether Gj > Gj-crit  where Gj-crit is Gcrit as described above, but adjusted for the correct value of the sample size; i.e. n is replaced by n − j + 1. Now let r be the largest value of j ≤ k such that Gj > Gj-crit. Then we conclude there are r outliers, namely x1, …, xr. If r = 0 there are no outliers.\n",
    "\n",
    "Note that if Gj > Gj-crit and h < j, then both xh and xj are outliers even if Gh ≤ Gh-crit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codes\n",
    "\n",
    "Following codes are for S-H-ESD where we bring in seasonality into picture, i.e., the anomalies are not just detected based on it's deviation and the critical value but also consideres the seasonal component. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking if the input 'num_obs_per_period' (number of obervarions in a period) is present\n",
    "if(is.null(num_obs_per_period)){\n",
    "        stop(\"must supply period length for time series decomposition\")\n",
    "}\n",
    "\n",
    "\n",
    "num_obs <- nrow(data)\n",
    "\n",
    "# Check to make sure we have at least two periods worth of data for anomaly context\n",
    "if(num_obs < num_obs_per_period * 2){\n",
    "    stop(\"Anom detection needs at least 2 periods worth of data\")\n",
    "}\n",
    "\n",
    "# Check if our timestamps are posix\n",
    "posix_timestamp <- if (class(data[[1L]])[1L] == \"POSIXlt\") TRUE else FALSE\n",
    "\n",
    "# Handling NAs \n",
    "if (length(rle(is.na(c(NA,data[[2L]],NA)))$values)>3){\n",
    "  stop(\"Data contains non-leading NAs. We suggest replacing NAs with interpolated values (see na.approx in Zoo package).\")\n",
    "} else {\n",
    "  data <- na.omit(data)\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step 1: Decompose data. This returns a univarite remainder which will be used for anomaly detection.\n",
    "data_decomp <- stl(ts(data[[2L]], frequency = num_obs_per_period),s.window = \"periodic\", robust = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the seasonal component, and the median of the data to create the univariate remainder\n",
    "data <- data.frame(timestamp = data[[1L]], count = (data[[2L]]-data_decomp$time.series[,\"seasonal\"]-median(data[[2L]])))\n",
    "    \n",
    "# Store the smoothed seasonal component, plus the trend component for use in determining the \"expected values\" option\n",
    "data_decomp <- data.frame(timestamp=data[[1L]], \n",
    "                          count=(as.numeric(trunc(data_decomp$time.series[,\"trend\"]+data_decomp$time.series[,\"seasonal\"]))))\n",
    "\n",
    "if(posix_timestamp){\n",
    "        data_decomp <- format_timestamp(data_decomp)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maximum number of outliers that S-H-ESD can detect (e.g. 49% of data)\n",
    "max_outliers <- trunc(num_obs*k)\n",
    "\n",
    "if(max_outliers == 0){\n",
    "  stop(paste0(\"With longterm=TRUE, AnomalyDetection splits the data into 2 week periods by default. \n",
    "        You have \", num_obs, \" observations in a period, which is too few. Set a higher piecewise_median_period_weeks.\"))\n",
    "}\n",
    "\n",
    "\n",
    "func_ma <- match.fun(median)\n",
    "func_sigma <- match.fun(mad)\n",
    "\n",
    "## Define values and vectors.\n",
    "# Defining R_idx to store the maximum number of outliers\n",
    "n <- length(data[[2L]])\n",
    "if (posix_timestamp){\n",
    "    R_idx <- as.POSIXlt(data[[1L]][1L:max_outliers], tz = \"UTC\")\n",
    "} else {\n",
    "    R_idx <- 1L:max_outliers\n",
    "}\n",
    "\n",
    "#Initialising the number of outliers to zero initially\n",
    "num_anoms <- 0L\n",
    "\n",
    "# Compute test statistic until r=max_outliers values have been\n",
    "# removed from the sample.\n",
    "for (i in 1L:max_outliers){\n",
    "    if(verbose) message(paste(i,\"/\", max_outliers,\"completed\"))\n",
    "\n",
    "    #Subtracting the median value from the data to make it consistent    \n",
    "    if(one_tail){\n",
    "        if(upper_tail){\n",
    "            ares <- data[[2L]] - func_ma(data[[2L]])\n",
    "        } else {\n",
    "            ares <- func_ma(data[[2L]]) - data[[2L]]\n",
    "        }\n",
    "    } else {\n",
    "        ares = abs(data[[2L]] - func_ma(data[[2L]]))\n",
    "    }\n",
    "\n",
    "    # protect against constant time series\n",
    "    data_sigma <- func_sigma(data[[2L]])\n",
    "    if(data_sigma == 0) \n",
    "        break\n",
    "# Dividing ares by mad (mean absolute deviation)\n",
    "    ares <- ares/data_sigma\n",
    "    R <- max(ares)\n",
    "\n",
    "        \n",
    "    temp_max_idx <- which(ares == R)[1L]\n",
    "\n",
    "    R_idx[i] <- data[[1L]][temp_max_idx]\n",
    "\n",
    "    #Removing the outlier point from the data set and using the data set for further outlier detection    \n",
    "    data <- data[-which(data[[1L]] == R_idx[i]), ]\n",
    "\n",
    "    ## Compute critical value.\n",
    "    if(one_tail){\n",
    "        p <- 1 - alpha/(n-i+1)\n",
    "    } else {\n",
    "        p <- 1 - alpha/(2*(n-i+1))\n",
    "    }\n",
    "\n",
    "     t <- qt(p,(n-i-1L))\n",
    "    lam <- t*(n-i) / sqrt((n-i-1+t**2)*(n-i+1))\n",
    "\n",
    "    if(R > lam)\n",
    "        num_anoms <- i\n",
    "}\n",
    "\n",
    "\n",
    "#Checking if we have got any anomalies        \n",
    "if(num_anoms > 0) {\n",
    "  R_idx <- R_idx[1L:num_anoms]\n",
    "} else {\n",
    "  R_idx = NULL\n",
    "}\n",
    "\n",
    "#Output list containing anomalies and thier position        \n",
    "anom_list <- list(anoms = R_idx, stl = data_decomp)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anom_list will containt the anomalies along with their respective position in a list format1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
