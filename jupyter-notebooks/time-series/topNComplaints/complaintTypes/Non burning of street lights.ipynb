{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Check if the series needs / benefits from a BoxCox transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadData <- function(dataFolder) {\n",
    "    files <- list.files(dataFolder)\n",
    "    data <- list()\n",
    "    for(file in files) {    \n",
    "        df <- read.csv(paste0(dataFolder, \"/\", file), stringsAsFactors=F)    \n",
    "        minYear <- min(df$Year)\n",
    "        complaintType <- substr(file,1,(nchar(file))-4)    \n",
    "        tsObject <- ts(df$Complaints, start=c(minYear, 1), frequency = 12)\n",
    "        data[[complaintType]] <- tsObject\n",
    "    }\n",
    "    data\n",
    "}\n",
    "data <- loadData(\"../../data/topNComplaints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series <- data[[\"Non Burning of Street Lights\"]]\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsdisplay(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data before 2012 are too few to consider\n",
    "train_start <- c(2012,4)\n",
    "series <- window(series, start=train_start, end=c(2016, 6))\n",
    "tsdisplay(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up data \n",
    "\n",
    "Although this data looks like it doesn't have any outliers, let's take a look at where the potential extreme values are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series, col=\"red\", lty=2)\n",
    "lines(tsclean(series), lty=1)\n",
    "legend(\"topright\", col=c(\"red\", \"black\"), lty=c(2,1), legend=c(\"Original\", \"Cleaned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series.cleaned <- tsclean(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a call here that the data doesn't contain any outliers, so we're leaving the data as it is\n",
    "\n",
    "## Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first try a static seasonal component\n",
    "plot(stl(series, s.window=\"periodic\"))\n",
    "\n",
    "\n",
    "#Comparing the plot with the decomposition of training data alone\n",
    "plot(stl(window(series,end = c(2015,6)) , s.window=\"periodic\"))\n",
    "\n",
    "#From the plot, it seems that there are some minor and intricate seasonality differences between the \n",
    "#training and overall data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend component is the most significant here, so the series probably needs some differencing. Strangely, there is also a seasonal component. Let's take varying s.window to see if changes over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old.par <- par(mfrow=c(2, 2), mar=c(3,3,3,3))\n",
    "plot(stl(series, s.window=3)$time.series[, 1], main=\"Seasonal Component with s.window = 3\")\n",
    "plot(stl(series, s.window=6)$time.series[, 1], main=\"Seasonal Component with s.window = 6\")\n",
    "plot(stl(series, s.window=10)$time.series[, 1], main=\"Seasonal Component with s.window = 10\")\n",
    "plot(stl(series, s.window=12)$time.series[, 1], main=\"Seasonal Component with s.window = 12\")\n",
    "par(old.par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the seasonal component is there, but $s.window=3$ suggests that it is not as significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasonal <- stl(series, s.window=\"periodic\")$time.series[, 1] # change s.window\n",
    "plot(seasonal, col=\"grey\")\n",
    "month <- 11 # change this to month you want\n",
    "for(i in 2012:2016) {    \n",
    "    abline(v=(month-1)/12 + i, lty=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looks like it peaks in November. **\n",
    "\n",
    "Let us then do a seasonal adjustment of the data. All further analysis should be done on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stl.fit <- stl(series, s.window=\"periodic\")\n",
    "series.adj <- seasadj(stl.fit)\n",
    "tsdisplay(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stl.cleaned.fit <- stl(series.cleaned, s.window=6)\n",
    "series.cleaned.adj <- seasadj(stl.cleaned.fit)\n",
    "tsdisplay(series.cleaned.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "### ARIMA models - estimating p, d, q\n",
    "\n",
    "First, let us estimate $d$. This is done by looking at the ACF of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Acf(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the above series is a classic example of a series that requires a diff of order 1, \n",
    "# so let's try that out and take a look at the Acf to see if it is overdifferenced\n",
    "series.diff <- diff(series.adj, lag=1, differences = 1)\n",
    "tsdisplay(series.diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the series looks good!\n",
    "# let's take a look at the standard deviation as well\n",
    "sd(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sd(series.diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looks good - it has decreased. Since stationary series return to the mean, let's take a look at that as well\n",
    "plot(series.diff, col=\"grey\")\n",
    "# a 2x4 MA\n",
    "lines(ma(ma(series.diff, order=2), order=4))\n",
    "abline(mean(series.diff), 0, col=\"blue\", lty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's verify once wheather d=1\n",
    "ndiffs(series.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to estimate p and q. To do this, we take a look at the PACF of the data. Note that this analysis is done on the differenced data. If we decide to fit a model with d=0, then we need to perform this analysis for the un-differenced data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for d=0\n",
    "Pacf(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looks like a AR(1) and a MA(5) process\n",
    "# take a look at the d=1\n",
    "Pacf(series.diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this looks like a MA(11) and a AR(4) process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelArima <- function(series, order, h, testData = NULL) {\n",
    "    fit <- Arima(series, order=order)\n",
    "    print(summary(fit))\n",
    "    predictions <- forecast(fit, h)\n",
    "    # compute max and min y\n",
    "    min.yvalue <- min(min(series), min(testData))\n",
    "    max.yvalue <- max(max(series), max(testData))\n",
    "    \n",
    "    plot(predictions, ylim=c(min.yvalue, max.yvalue))\n",
    "    if(!is.null(testData)) {\n",
    "        lines(testData, col=\"red\", lty=2)\n",
    "        print(accuracy(predictions, testData))\n",
    "    }\n",
    "    # check if residuals looklike white noise\n",
    "    Acf(residuals(fit), main=\"Residuals\")\n",
    "    # portmantaeu test\n",
    "    print(Box.test(residuals(fit), lag=24, fitdf=4, type=\"Ljung\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the series into a test and a train set\n",
    "series.train <- window(series.adj, end=c(2015, 6))\n",
    "series.test <- window(series.adj, start=c(2015, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with d=0, order=(1, 0, 5)\n",
    "modelArima(series.train, c(1, 0, 5), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with d=1, order=(4, 1, 11)\n",
    "modelArima(series.train, c(4, 1, 11), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fiddle with p and q, with d=1\n",
    "modelArima(series.train, c(5, 1, 11), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelArima(series.train, c(4, 1, 12), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelArima(series.train, c(4, 1, 10), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelArima(series.train, c(3, 1, 11), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# series = original data\n",
    "# series.cleaned = outliers removed\n",
    "# series.adj = original data, seasonally adjusted\n",
    "# series.cleaned.adj = cleaned data, seasonally adjusted\n",
    "# series.train = original seasonally adjusted data's train split\n",
    "# series.test = original seasonally adjusted data's test split\n",
    "# series.cleaned.train = cleaned seasonally adjusted data's train split\n",
    "# series.cleaned.test = cleaned seasonally adjusted data's test split\n",
    "\n",
    "# stl.fit = original data's stl\n",
    "# stl.cleaned.fit = cleaned data's stl \n",
    "# tsdisplay(series.adj)\n",
    "\n",
    "train_start = c(2012,4)\n",
    "train_end = c(2015,6)\n",
    "\n",
    "test_start = c(2015, 7)\n",
    "test_end = c(2016, 6)\n",
    "\n",
    "seasonal = stl.fit[[1]][,1]\n",
    "seasonal_cleaned = stl.cleaned.fit[[1]][,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function for finding the average of seasonal components\n",
    "period_stat <- function(ts_data_in, type = 1, start_value, years){\n",
    "    #type 1: sum\n",
    "    #type 2: mean\n",
    "\n",
    "    freq <- frequency(ts_data_in)\n",
    "    len <- length(ts_data_in)\n",
    "\n",
    "    freq_vector <- numeric(0)\n",
    "    freq_sum <- numeric(0)\n",
    "    vec <- numeric(0)\n",
    "    sum_vec <- numeric(0)\n",
    "\n",
    "    start_val <- start(ts_data_in)\n",
    "\n",
    "    ts_data_in <- c(rep(NA,start_val[2] - 1),ts_data_in)\n",
    "\n",
    "    max_limit <- ceiling(len/freq)\n",
    "    for(i in 1:max_limit){\n",
    "\n",
    "        vec <- ts_data_in[(((i-1)*freq)+1):(((i-1)*freq)+freq)]\n",
    "        freq_vector <- as.numeric(!is.na(vec))\n",
    "        vec[is.na(vec)] <- 0\n",
    "\n",
    "        if(i == 1){\n",
    "            sum_vec <- vec\n",
    "            freq_sum <- freq_vector\n",
    "            \n",
    "        }else{\n",
    "           \n",
    "            sum_vec <- sum_vec + vec\n",
    "            freq_sum <- freq_sum + freq_vector\n",
    "        }\n",
    "    }\n",
    "\n",
    "    final_ts <- numeric(0)\n",
    "    \n",
    "    if(type == 1)\n",
    "    {\n",
    "        final_ts <- sum_vec\n",
    "    }else if(type == 2) {\n",
    "\n",
    "        final_ts <- (sum_vec/freq_sum)\n",
    "    } else {\n",
    "        stop(\"Invalid type\")\n",
    "    }\n",
    "\n",
    "    return(ts(rep(final_ts,years),frequency = freq, start = start_value ))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adjust the negative values in the ts data\n",
    "min_ts_value <- min(series.adj)\n",
    "min_ts_cleaned_value <- min(series.cleaned.adj)\n",
    "\n",
    "bias_value <- (-1*min_ts_value) + 1\n",
    "bias_value_cleaned <- (-1*min_ts_cleaned_value) + 1\n",
    "\n",
    "#min(series)\n",
    "#min(series.cleaned)\n",
    "\n",
    "#min(series.adj)\n",
    "#min(series.cleaned.adj)\n",
    "\n",
    "ES_series <- series.adj + bias_value\n",
    "ES_series_cleaned <- series.cleaned.adj + bias_value_cleaned\n",
    "\n",
    "#plot(ES_series)\n",
    "\n",
    "train_data_adj <- window(ES_series,start = train_start, end=train_end)\n",
    "test_data_adj <- window(ES_series, start= test_start, end = test_end)\n",
    "\n",
    "train_data_adj_cleaned <- window(ES_series_cleaned,start = train_start, end = train_end)\n",
    "test_data_adj_cleaned <- window(ES_series_cleaned, start = test_start, end = test_end)\n",
    "\n",
    "train_data <- window(series, start = train_start, end = train_end)\n",
    "test_data <- window(series, start = test_start, end = test_end)\n",
    "\n",
    "train_data_cleaned <- window(series.cleaned, start = train_start, end = train_end)\n",
    "test_data_cleaned <- window(series.cleaned, start = test_start, end = test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the mean value from the seasonal components for the data set and not for the training set alone.\n",
    "#Need to adjust based on the input from Suchana.\n",
    "\n",
    "seasonal_mean <- period_stat(seasonal,2,c(2012,1),years = 7)\n",
    "seasonal_cleaned_mean <- period_stat(seasonal_cleaned,2,c(2012,1),years = 7)\n",
    "\n",
    "plot(seasonal_mean)\n",
    "plot(seasonal_cleaned_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing data. Removing 0 from the data\n",
    "train_data_adj[train_data_adj==0]=0.01 \n",
    "train_data_adj_cleaned[train_data_adj_cleaned==0]=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best fit for exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_types = c(\"ANN\",\"AAN\",\"AAA\",\"ANA\",\"MNN\",\"MAN\",\"MNA\",\"MAA\",\"MMN\",\"MNM\",\"MMM\",\"MAM\")\n",
    "forecast_values = 12\n",
    "# For eg: AAA -> additive level, additive trend and additive seasonality\n",
    "# ANN -> No trend or seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function:  For trying out various possible models in Exponential smoothing, and picking the best with MAPE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_function <- function(train_data, test_data)\n",
    "{    \n",
    "    all_fit <- list()\n",
    "    test_models <- list()\n",
    "\n",
    "    print(\"Fitting various models: \")\n",
    "    for (bool in c(TRUE,FALSE)){\n",
    "        for (model_type in all_types){\n",
    "\n",
    "            if(bool & substr(model_type,2,2)==\"N\"){\n",
    "                next\n",
    "            }\n",
    "        test_model = ets(train_data, model = model_type,damped = bool)\n",
    "        #Box.test(test_model$residuals, lag = 20, type = \"Ljung-Box\")$p.value\n",
    "        all_fit[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]][1] <- \n",
    "                                                    accuracy(f = forecast.ets(test_model,h=forecast_values)$mean,x = test_data)[5]\n",
    "        all_fit[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]][2] <- \n",
    "                                                    100*(Box.test(test_model$residuals, lag = 20, type = \"Ljung-Box\")$p.value)\n",
    "\n",
    "            \n",
    "            test_models[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]] <- test_model\n",
    "\n",
    "            print(test_model$method)\n",
    "            print(accuracy(f = forecast.ets(test_model,h=forecast_values)$mean, x = test_data)[5])\n",
    "            print(\"\")\n",
    "\n",
    "            #Excluding the models which has auto correlated residuals @ 10% significance level\n",
    "\n",
    "        }\n",
    "    }\n",
    "    return(list(all_fit,test_models))\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitting the models for all types of data - Original, cleaned, seasonally adjusted, cleaned - seasonally adjusted\n",
    "\n",
    "models_adj <- fit_function(train_data_adj,test_data_adj) #Seasonally adjusted data\n",
    "models_adj_cleaned <- fit_function(train_data_adj_cleaned,test_data_adj_cleaned) #Seasonally adjusted, cleaned(with outliers being removed) data\n",
    "\n",
    "models <- fit_function(train_data,test_data) #Original data\n",
    "models_cleaned <- fit_function(train_data_cleaned, test_data_cleaned) #Original, cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fit_adj <- models_adj[[1]]\n",
    "test_models_adj <- models_adj[[2]]\n",
    "\n",
    "all_fit_adj_cleaned<- models_adj_cleaned[[1]]\n",
    "test_models_adj_cleaned <- models_adj_cleaned[[2]]\n",
    "\n",
    "all_fit <- models[[1]]\n",
    "test_models <- models[[2]]\n",
    "\n",
    "all_fit_cleaned <- models_cleaned[[1]]\n",
    "test_models_cleaned <- models_cleaned[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Case 1: Identifying the best fit for seasonally adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit_adj\n",
    "    if(length(proper_models)==0){\n",
    "        print(\"None of the model satisfies - Ljung-Box test; Model with least 3 p values taken\")\n",
    "        p_values <- sapply(all_fit_adj, function(x)x[2])\n",
    "        proper_models <- all_fit_adj[order(p_values)][1:3]\n",
    "    }\n",
    "\n",
    "    best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "    best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "    print(paste0(\"Best Model:\",best_model))\n",
    "    print(paste0(\"Best Mape: \",best_mape))\n",
    "\n",
    "#Finding top n fits\n",
    "#top_models <- c()\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models_adj <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Identifying the best for cleaned, seasonlly adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit_adj_cleaned\n",
    "    \n",
    "    if(length(proper_models)==0){\n",
    "        print(\"None of the model satisfies - Ljung-Box test; Model with least 3 p values taken\")\n",
    "        p_values <- sapply(all_fit_adj_cleaned, function(x)x[2])\n",
    "        proper_models <- all_fit_adj_cleaned[order(p_values)][1:3]\n",
    "    }\n",
    "\n",
    "    best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "    best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "    print(paste0(\"Best Model:\",best_model))\n",
    "    print(paste0(\"Best Mape: \",best_mape))\n",
    "        \n",
    "#Finding top n fits\n",
    "#top_models <- c()\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models_adj_cleaned <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_cleaned_mean        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3: Identifying the best fit for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit\n",
    "    if(length(proper_models)==0){\n",
    "        print(\"None of the model satisfies - Ljung-Box test; Model with least 3 p values taken\")\n",
    "        p_values <- sapply(all_fit, function(x)x[2])\n",
    "        proper_models <- all_fit[order(p_values)][1:3]\n",
    "    }\n",
    "\n",
    "    best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "    best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "    print(paste0(\"Best Model:\",best_model))\n",
    "    print(paste0(\"Best Mape: \",best_mape))\n",
    "        \n",
    "#Finding top n fits\n",
    "#top_models <- c()\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models<- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_cleaned_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 4: Identifying the best fit for cleaned original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit_cleaned\n",
    "    if(length(proper_models)==0){\n",
    "        print(\"None of the model satisfies - Ljung-Box test; Model with least 3 p values taken\")\n",
    "        p_values <- sapply(all_fit, function(x)x[2])\n",
    "        proper_models <- all_fit[order(p_values)][1:3]\n",
    "    }\n",
    "\n",
    "    best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "    best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "    print(paste0(\"Best Model:\",best_model))\n",
    "    print(paste0(\"Best Mape: \",best_mape))\n",
    "        \n",
    "#Finding top n fits\n",
    "#top_models <- c()\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models_cleaned <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_cleaned_mean    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot analysis\n",
    "#### Plot 1: Seasonally adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_series,col = \"black\")\n",
    "lines(test_data_adj, col = \"blue\")\n",
    "lines(forecast.ets(test_models_adj[[top_models_adj[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_adj[[top_models_adj[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_adj[[top_models_adj[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2: Seasonally adjusted & cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_series_cleaned,col = \"black\")\n",
    "lines(test_data_adj_cleaned, col = \"blue\")\n",
    "lines(forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 3: Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_fit\n",
    "#test_models[[all_fit[1]]]\n",
    "\n",
    "plot(series,col = \"black\")\n",
    "lines(test_data, col = \"blue\")\n",
    "\n",
    "accuracy(test_models[[top_models[1]]])\n",
    "accuracy(test_models[[top_models[2]]])\n",
    "accuracy(test_models[[top_models[3]]])\n",
    "\n",
    "lines(forecast.ets(test_models[[top_models[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models[[top_models[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models[[top_models[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 4: Cleaned original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy(test_models_cleaned[[top_models_cleaned[1]]])\n",
    "accuracy(test_models_cleaned[[top_models_cleaned[2]]])\n",
    "accuracy(test_models_cleaned[[top_models_cleaned[3]]])\n",
    "\n",
    "plot(series.cleaned,col = \"black\", ylim = c(200,2200))\n",
    "lines(test_data_cleaned, col = \"blue\")\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\",lty=c(1,1,1,1),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data(cleaned)\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting back the original data\n",
    "#### Case 1: Seasonally adjusted data (To bring back the original data, seasonal component and the Bias value is added back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Case 1: Seasonally adjusted data\")\n",
    "#Adding the bias value which was added to overcome the negative values\n",
    "ES_series_bias <- ES_series - bias_value\n",
    "test_series_bias <- test_data_adj - bias_value\n",
    "forecast1_bias <- forecast.ets(test_models_adj[[top_models_adj[1]]],h=12)$mean - bias_value\n",
    "forecast2_bias <- forecast.ets(test_models_adj[[top_models_adj[2]]],h=12)$mean - bias_value\n",
    "forecast3_bias <- forecast.ets(test_models_adj[[top_models_adj[3]]],h=12)$mean - bias_value\n",
    "\n",
    "#Adding back the seasonal value from stl decomposition\n",
    "ES_value_adj <- ES_series_bias + seasonal\n",
    "test_series_adj <- test_series_bias + seasonal\n",
    "\n",
    "#Adding back the mean seasonal component to the forecasted data\n",
    "forecast1_adj <- forecast1_bias + seasonal_mean\n",
    "forecast2_adj <- forecast2_bias + seasonal_mean\n",
    "forecast3_adj <- forecast3_bias + seasonal_mean\n",
    "\n",
    "#Calculating the accuracy of the training data\n",
    "accuracy(test_models_adj[[top_models_adj[1]]])\n",
    "accuracy(test_models_adj[[top_models_adj[2]]])\n",
    "accuracy(test_models_adj[[top_models_adj[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking the MAPE values with original data\n",
    "print(paste0(\"Top model: \", top_models_adj[1]))\n",
    "accuracy(forecast1_adj,test_series_adj)\n",
    "print(paste0(\"Top model: \", top_models_adj[2]))\n",
    "accuracy(forecast2_adj,test_series_adj)\n",
    "print(paste0(\"Top model: \", top_models_adj[3]))\n",
    "accuracy(forecast3_adj,test_series_adj)\n",
    "\n",
    "#accuracy(test_data, forecast.ets(test_models[[top_models[3]]],h=12)$mean )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Seasonally adjusted & cleaned data (To bring back the original data, seasonal component and the Bias value is added back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Case 2: Seasonally adjusted & cleaned data\")\n",
    "#Adding the bias value which was added to overcome the negative values\n",
    "\n",
    "\n",
    "ES_series_bias_cleaned <- ES_series_cleaned - bias_value_cleaned\n",
    "test_series_bias_cleaned <- test_data_adj_cleaned - bias_value_cleaned\n",
    "\n",
    "\n",
    "forecast1_bias <- forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[1]]],h=12)$mean - bias_value_cleaned\n",
    "forecast2_bias <- forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[2]]],h=12)$mean - bias_value_cleaned\n",
    "forecast3_bias <- forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[3]]],h=12)$mean - bias_value_cleaned\n",
    "\n",
    "#Adding back the seasonal value from stl decomposition\n",
    "ES_value_adj_cleaned <- ES_series_bias_cleaned + seasonal_cleaned\n",
    "test_series_adj_cleaned <- test_series_bias_cleaned + seasonal_cleaned\n",
    "\n",
    "#Adding back the mean seasonal component to the forecasted data\n",
    "forecast1_adj_cleaned <- forecast1_bias + seasonal_cleaned_mean\n",
    "forecast2_adj_cleaned <- forecast2_bias + seasonal_cleaned_mean\n",
    "forecast3_adj_cleaned <- forecast3_bias + seasonal_cleaned_mean\n",
    "\n",
    "#Calculating the accuracy of the training data\n",
    "accuracy(test_models_adj_cleaned[[top_models_adj_cleaned[1]]])\n",
    "accuracy(test_models_adj_cleaned[[top_models_adj_cleaned[2]]])\n",
    "accuracy(test_models_adj_cleaned[[top_models_adj_cleaned[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking the MAPE values with original data\n",
    "print(paste0(\"Top model: \", top_models_adj_cleaned[1]))\n",
    "accuracy(forecast1_adj_cleaned,test_series_adj_cleaned)\n",
    "print(paste0(\"Top model: \", top_models_adj_cleaned[2]))\n",
    "accuracy(forecast2_adj_cleaned,test_series_adj_cleaned)\n",
    "print(paste0(\"Top model: \", top_models_adj_cleaned[3]))\n",
    "accuracy(forecast3_adj_cleaned,test_series_adj_cleaned)\n",
    "\n",
    "top_models\n",
    "\n",
    "#accuracy(forecast.ets(test_models[[top_models[1]]],h=12)$mean, test_data)\n",
    "\n",
    "#accuracy(test_data, forecast.ets(test_models[[top_models[3]]],h=12)$mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ljung Box test - One of the checks to perform stationarity of TS data\n",
    "# A small function\n",
    "residual_analyis <- function(model_name){\n",
    "    print(model_name)\n",
    "    print(Box.test(test_models[[model_name]]$residuals, lag = 20, type = \"Ljung-Box\"))\n",
    "    #p_value <- Box.test(test_models[[model_name]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "    Acf(test_models[[model_name]]$residuals, main = model_name)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 1: Seasonally adjusted models\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models_adj[1]) #Top model\n",
    "residual_analyis(top_models_adj[2]) #Second best model\n",
    "residual_analyis(top_models_adj[3]) #Third best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 2 - Seasonally adjusted cleaned models\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models_adj_cleaned[1]) #Top model\n",
    "residual_analyis(top_models_adj_cleaned[2]) #Second best model\n",
    "residual_analyis(top_models_adj_cleaned[3]) #Third best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 3 - Models on original data\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models[1]) #Top model\n",
    "residual_analyis(top_models[2]) #Second best model\n",
    "residual_analyis(top_models[3]) #Third best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 4 - Models on original data\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models_cleaned[1]) #Top model\n",
    "residual_analyis(top_models_cleaned[2]) #Second best model\n",
    "residual_analyis(top_models_cleaned[3]) #Third best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual output: The top two models across all four cases seem to be slighly autocorrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output:\n",
    "#### Analysing each case and figuring out the most suitable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Model for seasonally adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_value_adj,col = \"black\", ylab = \"No of complaints\", \n",
    "                 main = \"Model with seasonal adjustment\")\n",
    "\n",
    "lines(test_series_adj, col = \"blue\") #Original test data\n",
    "\n",
    "\n",
    "accuracy(forecast1_adj,test_series_adj)\n",
    "accuracy(forecast2_adj,test_series_adj)\n",
    "accuracy(forecast3_adj,test_series_adj)\n",
    "\n",
    "\n",
    "lines(test_series_bias + seasonal_mean, col = \"brown\", lty =2) #Deseasonlised data with average seasonal component applied\n",
    "lines(forecast1_adj, col = \"red\") #Top model\n",
    "lines(forecast2_adj, col = \"green\") #Top second model\n",
    "lines(forecast3_adj, col = \"yellow\") #Top third model\n",
    "\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\",\"test data with seasonal mean\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: A great fit whose forecasts capture seasonality very well. MAPE values are also significantly less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Case 2: Model for seasonally adjusted and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_value_adj_cleaned,col = \"black\", ylab = \"No of complaints\",\n",
    "                 main = \"Model with seasonal adjustment and cleaning\") \n",
    "lines(test_series_adj_cleaned, col = \"blue\") #Original test data\n",
    "\n",
    "\n",
    "\n",
    "accuracy(forecast1_adj_cleaned,test_series_adj_cleaned)\n",
    "accuracy(forecast2_adj_cleaned,test_series_adj_cleaned)\n",
    "accuracy(forecast3_adj_cleaned,test_series_adj_cleaned)\n",
    "\n",
    "\n",
    "lines(test_series_bias_cleaned + seasonal_cleaned_mean, col = \"brown\", lty =2) #Deseasonlised data with average seasonal component applied\n",
    "lines(forecast1_adj_cleaned, col = \"red\") #Top model\n",
    "lines(forecast2_adj_cleaned, col = \"green\") #Top second model\n",
    "lines(forecast3_adj_cleaned, col = \"yellow\") #Top third model\n",
    "\n",
    "\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\",\"test data with seasonal mean\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: With cleaned data, the model is better with lesser MAPE values. Except the small peak at the end of 2015 other forecasts are almost spot on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: Model for the original data as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series,col = \"black\", ylab = \"No of complaints\",\n",
    "                 main = \"Model with original data\") \n",
    "lines(test_data, col = \"blue\") #Originayl test data\n",
    "\n",
    "\n",
    "accuracy(forecast.ets(test_models[[top_models[1]]],h=12)$mean,test_data)\n",
    "accuracy(forecast.ets(test_models[[top_models[2]]],h=12)$mean,test_data)\n",
    "accuracy(forecast.ets(test_models[[top_models[3]]],h=12)$mean,test_data)\n",
    "\n",
    "\n",
    "lines(forecast.ets(test_models[[top_models[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models[[top_models[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models[[top_models[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly\n",
    "\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\",\"test data with seasonal mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Even though MAPE values are less for some models, they hardly capture the desired seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4: Model for original data which is cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12))\n",
    "\n",
    "plot(series.cleaned,col = \"black\", ylim = c(300,2300),main = \"Model with cleaned data\")\n",
    "lines(test_data_cleaned, col = \"blue\")\n",
    "#lines(test_data, col = \"brown\", lty = 2)\n",
    "\n",
    "accuracy(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12)$mean,test_data_cleaned)\n",
    "accuracy(forecast.ets(test_models_cleaned[[top_models_cleaned[2]]],h=12)$mean,test_data_cleaned)\n",
    "accuracy(forecast.ets(test_models_cleaned[[top_models_cleaned[3]]],h=12)$mean,test_data_cleaned)\n",
    "\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data(cleaned)\", \"Best model\", \"Second best\", \"Third best\",\"Actual test data\"))\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Only the best model captures the seasonality but also suffers a constant bias. Interestingly, even though other two models have more or less the same MAPE they don't have any trend or seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: From the MAPE values and the plot observations, the forecasting model works best for seasonally adjusted data. More specifically, the model created for seasonally adjusted cleaned data seems to give best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
