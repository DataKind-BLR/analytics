{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "library(tseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadData <- function(dataFolder) {\n",
    "    files <- list.files(dataFolder)\n",
    "    data <- list()\n",
    "    for(file in files) {    \n",
    "        df <- read.csv(paste0(dataFolder, \"/\", file), stringsAsFactors=F)    \n",
    "        minYear <- min(df$Year)\n",
    "        complaintType <- substr(file,1,(nchar(file))-4)    \n",
    "        tsObject <- ts(df$Complaints, start=c(minYear, 1), frequency = 12)\n",
    "        data[[complaintType]] <- tsObject\n",
    "    }\n",
    "    data\n",
    "}\n",
    "data <- loadData(\"../../data/topNComplaints\")\n",
    "\n",
    "# change dates if data changes\n",
    "train_stop <- c(2015, 6)\n",
    "test_start <- c(2015, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series <- data[[\"Dog menace \"]]\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data before 2012 are too few to consider\n",
    "train_start <- c(2012, 4)\n",
    "series <- window(series, start=train_start, end=c(2016, 9))\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsdisplay(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series, col=\"red\", lty=2)\n",
    "lines(tsclean(series), lty=1)\n",
    "legend(\"topright\", col=c(\"red\", \"black\"), lty=c(2,1), legend=c(\"Original\", \"Cleaned\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series.cleaned <- tsclean(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no significant outliers, and the data is clean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition\n",
    "Let's see if there is a seasonal component in this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Comparing the seasonality of entire dataset and the training data\n",
    "plot(stl(series, s.window=\"periodic\"))\n",
    "# The series does look like it has a seasonal component - let's take a look at that.\n",
    "\n",
    "plot(stl(window(series,end = c(2015,6)), s.window=\"periodic\"))\n",
    "# The series does look like it has a seasonal component - let's take a look at that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: From the plot and the data points, it looks like the seasonality varies slightly for recent time period(test data), which is not exactly the same as that of trianing dataset, which in turn may mildly affect the future predictions if we consider only the seasonality of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(stl(series, s.window=6)) # change s.window to something that make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's take a look at which month this series peaks\n",
    "# looks like there are two spikes, one in march and the other in september\n",
    "# the data does contain another spike in between the two - which isn't apparent in the \n",
    "# seasonal component\n",
    "seasonal <- stl(series, s.window=6)$time.series[, 1] # change s.window\n",
    "plot(seasonal, col=\"grey\")\n",
    "month1 <- 9 # september\n",
    "month2 <- 3 # march\n",
    "for(i in 2012:2016) {    \n",
    "    abline(v=(month1-1)/12 + i, lty=2)\n",
    "    abline(v=(month2-1)/12 + i, lty=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's superimpose this on the original data, to see if this effect \n",
    "# is significant\n",
    "plot(series, col=\"grey\")\n",
    "month1 <- 9\n",
    "month2 <- 3\n",
    "for(i in 2012:2016) {    \n",
    "    abline(v=(month1-1)/12 + i, lty=2)\n",
    "    abline(v=(month2-1)/12 + i, lty=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this series looks like it fits the data well - since the seasonal component does seem to increase as time progresses\n",
    "# let's set s.window = \"periodic\"\n",
    "stl.fit <- stl(series, s.window=\"periodic\")\n",
    "series.adj <- seasadj(stl.fit)\n",
    "tsdisplay(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stl.cleaned.fit <- stl(series.cleaned, s.window=6)\n",
    "series.cleaned.adj <- seasadj(stl.cleaned.fit)\n",
    "tsdisplay(series.cleaned.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "### ARIMA models - estimating p, d, q\n",
    "\n",
    "First, let us estimate $d$. This is done by looking at the ACF of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Acf(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the above series is a classic example of a series that requires a diff of order 1, \n",
    "# so let's try that out and take a look at the Acf to see if it is overdifferenced\n",
    "tsdisplay(diff(series.adj, lag=1, differences = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# looks like the series has a strong, negative ACF at lag12 \n",
    "# indicating a possible seasonality? \n",
    "# let's also look at d=2\n",
    "tsdisplay(diff(series.adj, lag = 1, differences = 2))\n",
    "# this is clearly overdifferenced, so d <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look at standard-deviation\n",
    "sd.0 <- sd(series.adj)\n",
    "sd.1 <- sd(diff(series.adj, differences = 1))\n",
    "sd.2 <- sd(diff(series.adj, differences = 2))\n",
    "print(paste0(\"SD with d = 0: \", sd.0, \", SD with d = 1: \", sd.1, \", SD with d = 2: \", sd.2))\n",
    "# in terms of sd, d=1 is a better fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series.diff <- diff(series.adj, lag=1, differences = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series.diff, col=\"grey\")\n",
    "# a 2x4 MA\n",
    "lines(ma(ma(series.diff, order=2), order=4))\n",
    "abline(mean(series.diff), 0, col=\"blue\", lty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndiffs(series.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to estimate p and q. To do this, we take a look at the PACF of the data. Note that this analysis is done on the differenced data. If we decide to fit a model with d=0, then we need to perform this analysis for the un-differenced data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let d=0 first\n",
    "# looks like a AR(1), MA(4)\n",
    "Pacf(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's try with d=1\n",
    "# looks like MA(12) process, possibly an AR(3)\n",
    "Pacf(series.diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelArima <- function(series, order, h, testData = NULL, lambda=NULL) {\n",
    "    fit <- Arima(series, order=order, lambda = lambda)\n",
    "    print(summary(fit))\n",
    "    predictions <- forecast(fit, h, lambda = lambda)\n",
    "    # compute max and min y\n",
    "    min.yvalue <- min(min(series), min(testData))\n",
    "    max.yvalue <- max(max(series), max(testData))\n",
    "    \n",
    "    plot(predictions, ylim=c(min.yvalue, max.yvalue))\n",
    "    if(!is.null(testData)) {\n",
    "        lines(testData, col=\"red\", lty=2)\n",
    "        print(accuracy(predictions, testData))\n",
    "    }\n",
    "    # check if residuals looklike white noise\n",
    "    Acf(residuals(fit), main=\"Residuals\")\n",
    "    # portmantaeu test\n",
    "    print(Box.test(residuals(fit), lag=24, fitdf=4, type=\"Ljung\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the series into a test and a train set\n",
    "series.train <- window(series.adj, end=train_stop)\n",
    "series.test <- window(series.adj, start=test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelArima(series.train, c(1, 0, 4), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelArima(series.train, c(3, 1, 12), length(series.test), series.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Experimentation using BoxCox transforms\n",
    "The series, even after differencing appears to be non-stationary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf.test(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf.test(series.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adf.test(series.diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's try a BoxCox transform\n",
    "est.lambda <- BoxCox.lambda(series.diff)\n",
    "est.lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is for diffed\n",
    "adf.test(BoxCox(series.diff, lambda = est.lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the series out once\n",
    "tsdisplay(BoxCox(series.diff, lambda = est.lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's retry the models with lambda\n",
    "modelArima(series.train, c(1, 0, 4), length(series.test), series.test, lambda = BoxCox.lambda(series.adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelArima(series.train, c(3, 1, 12), length(series.test), series.test, est.lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# series = original data\n",
    "# series.cleaned = outliers removed\n",
    "# series.adj = original data, seasonally adjusted\n",
    "# series.cleaned.adj = cleaned data, seasonally adjusted\n",
    "# series.train = original seasonally adjusted data's train split\n",
    "# series.test = original seasonally adjusted data's test split\n",
    "# series.cleaned.train = cleaned seasonally adjusted data's train split\n",
    "# series.cleaned.test = cleaned seasonally adjusted data's test split\n",
    "\n",
    "# stl.fit = original data's stl\n",
    "# stl.cleaned.fit = cleaned data's stl \n",
    "# tsdisplay(series.adj)\n",
    "\n",
    "train_start = c(2012,4)\n",
    "train_end = c(2015,6)\n",
    "\n",
    "test_start = c(2015, 7)\n",
    "test_end = c(2016, 6)\n",
    "\n",
    "seasonal = stl.fit[[1]][,1]\n",
    "seasonal_cleaned = stl.cleaned.fit[[1]][,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function for finding the average of seasonal components\n",
    "period_stat <- function(ts_data_in, type = 1, start_value, years){\n",
    "    #type 1: sum\n",
    "    #type 2: mean\n",
    "\n",
    "    freq <- frequency(ts_data_in)\n",
    "    len <- length(ts_data_in)\n",
    "\n",
    "    freq_vector <- numeric(0)\n",
    "    freq_sum <- numeric(0)\n",
    "    vec <- numeric(0)\n",
    "    sum_vec <- numeric(0)\n",
    "\n",
    "    start_val <- start(ts_data_in)\n",
    "\n",
    "    ts_data_in <- c(rep(NA,start_val[2] - 1),ts_data_in)\n",
    "\n",
    "    max_limit <- ceiling(len/freq)\n",
    "    for(i in 1:max_limit){\n",
    "\n",
    "        vec <- ts_data_in[(((i-1)*freq)+1):(((i-1)*freq)+freq)]\n",
    "        freq_vector <- as.numeric(!is.na(vec))\n",
    "        vec[is.na(vec)] <- 0\n",
    "\n",
    "        if(i == 1){\n",
    "            sum_vec <- vec\n",
    "            freq_sum <- freq_vector\n",
    "            \n",
    "        }else{\n",
    "           \n",
    "            sum_vec <- sum_vec + vec\n",
    "            freq_sum <- freq_sum + freq_vector\n",
    "        }\n",
    "    }\n",
    "\n",
    "    final_ts <- numeric(0)\n",
    "    \n",
    "    if(type == 1)\n",
    "    {\n",
    "        final_ts <- sum_vec\n",
    "    }else if(type == 2) {\n",
    "\n",
    "        final_ts <- (sum_vec/freq_sum)\n",
    "    } else {\n",
    "        stop(\"Invalid type\")\n",
    "    }\n",
    "\n",
    "    return(ts(rep(final_ts,years),frequency = freq, start = start_value ))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adjust the negative values in the ts data\n",
    "min_ts_value <- min(series.adj)\n",
    "min_ts_cleaned_value <- min(series.cleaned.adj)\n",
    "\n",
    "bias_value <- (-1*min_ts_value) + 1\n",
    "bias_value_cleaned <- (-1*min_ts_cleaned_value) + 1\n",
    "\n",
    "#min(series)\n",
    "#min(series.cleaned)\n",
    "\n",
    "#min(series.adj)\n",
    "#min(series.cleaned.adj)\n",
    "\n",
    "ES_series <- series.adj + bias_value\n",
    "ES_series_cleaned <- series.cleaned.adj + bias_value_cleaned\n",
    "\n",
    "\n",
    "#plot(ES_series)\n",
    "\n",
    "train_data_adj <- window(ES_series,start = train_start, end=train_end)\n",
    "test_data_adj <- window(ES_series, start= test_start, end = test_end)\n",
    "\n",
    "train_data_adj_cleaned <- window(ES_series_cleaned,start = train_start, end = train_end)\n",
    "test_data_adj_cleaned <- window(ES_series_cleaned, start = test_start, end = test_end)\n",
    "\n",
    "train_data <- window(series, start = train_start, end = train_end)\n",
    "test_data <- window(series, start = test_start, end = test_end)\n",
    "\n",
    "train_data_cleaned <- window(series.cleaned, start = train_start, end = train_end)\n",
    "test_data_cleaned <- window(series.cleaned, start = test_start, end = test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the mean value from the seasonal components for the data set and not for the training set alone.\n",
    "#Need to adjust based on the input from Suchana.\n",
    "\n",
    "seasonal_mean <- period_stat(seasonal,2,c(2012,1),years = 7)\n",
    "seasonal_cleaned_mean <- period_stat(seasonal_cleaned,2,c(2012,1),years = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing data. Removing 0 from the data\n",
    "train_data_adj[train_data_adj==0]=0.01 \n",
    "train_data_adj_cleaned[train_data_adj_cleaned==0]=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best fit for exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_types = c(\"ANN\",\"AAN\",\"AAA\",\"ANA\",\"MNN\",\"MAN\",\"MNA\",\"MAA\",\"MMN\",\"MNM\",\"MMM\",\"MAM\")\n",
    "forecast_values = 12\n",
    "# For eg: AAA -> additive level, additive trend and additive seasonality\n",
    "# ANN -> No trend or seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function:  For trying out various possible models in Exponential smoothing, and picking the best with MAPE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_function <- function(train_data, test_data)\n",
    "{    \n",
    "    all_fit <- list()\n",
    "    test_models <- list()\n",
    "\n",
    "    print(\"Fitting various models: \")\n",
    "    for (bool in c(TRUE,FALSE)){\n",
    "        for (model_type in all_types){\n",
    "\n",
    "            if(bool & substr(model_type,2,2)==\"N\"){\n",
    "                next\n",
    "            }\n",
    "        test_model = ets(train_data, model = model_type,damped = bool)\n",
    "        #Box.test(test_model$residuals, lag = 20, type = \"Ljung-Box\")$p.value\n",
    "        all_fit[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]][1] <- \n",
    "                                                    accuracy(f = forecast.ets(test_model,h=forecast_values)$mean,x = test_data)[5]\n",
    "        all_fit[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]][2] <- \n",
    "                                                    100*(Box.test(test_model$residuals, lag = 20, type = \"Ljung-Box\")$p.value)\n",
    "\n",
    "            \n",
    "            test_models[[paste0(\"ETS Model: \",model_type,\", Damped: \",bool)]] <- test_model\n",
    "\n",
    "            print(test_model$method)\n",
    "            print(accuracy(f = forecast.ets(test_model,h=forecast_values)$mean, x = test_data)[5])\n",
    "            print(\"\")\n",
    "\n",
    "            #Excluding the models which has auto correlated residuals @ 10% significance level\n",
    "\n",
    "        }\n",
    "    }\n",
    "    return(list(all_fit,test_models))\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitting the models for all types of data - Original, cleaned, seasonally adjusted, cleaned - seasonally adjusted\n",
    "\n",
    "models_adj <- fit_function(train_data_adj,test_data_adj) #Seasonally adjusted data\n",
    "models_adj_cleaned <- fit_function(train_data_adj_cleaned,test_data_adj_cleaned) #Seasonally adjusted, cleaned(with outliers being removed) data\n",
    "\n",
    "models <- fit_function(train_data,test_data) #Original data\n",
    "models_cleaned <- fit_function(train_data_cleaned, test_data_cleaned) #Original, cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fit_adj <- models_adj[[1]]\n",
    "test_models_adj <- models_adj[[2]]\n",
    "\n",
    "all_fit_adj_cleaned<- models_adj_cleaned[[1]]\n",
    "test_models_adj_cleaned <- models_adj_cleaned[[2]]\n",
    "\n",
    "all_fit <- models[[1]]\n",
    "test_models <- models[[2]]\n",
    "\n",
    "all_fit_cleaned <- models_cleaned[[1]]\n",
    "test_models_cleaned <- models_cleaned[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1: Identifying the best fit for seasonally adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit_adj\n",
    "\n",
    "best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "print(paste0(\"Best Model:\",best_model))\n",
    "print(paste0(\"Best Mape: \",best_mape))\n",
    "\n",
    "#Finding top n fits\n",
    "Top_n <- 3\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models_adj <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Identifying the best for cleaned, seasonlly adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit_adj_cleaned\n",
    "\n",
    "best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "print(paste0(\"Best Model:\",best_model))\n",
    "print(paste0(\"Best Mape: \",best_mape))\n",
    "        \n",
    "#Finding top n fits\n",
    "#top_models <- c()\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models_adj_cleaned <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_cleaned_mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3: Identifying the best fit for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit\n",
    "\n",
    "best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "print(paste0(\"Best Model:\",best_model))\n",
    "print(paste0(\"Best Mape: \",best_mape))\n",
    "\n",
    "#Finding top n fits\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_cleaned_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 4: Identifying the best fit for cleaned original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the best fit\n",
    "proper_models <- all_fit_cleaned\n",
    "\n",
    "best_mape <- min(sapply(proper_models,function(x)x[1]))\n",
    "best_model <- names(which.min(sapply(proper_models,function(x)x[1])))\n",
    "\n",
    "print(paste0(\"Best Model:\",best_model))\n",
    "print(paste0(\"Best Mape: \",best_mape))\n",
    "        \n",
    "#Finding top n fits\n",
    "Top_n <- 3\n",
    "\n",
    "if(length(proper_models)<3){Top_n <- length(proper_models)}\n",
    "\n",
    "top_mape_val <- proper_models[order(sapply(proper_models, function(x)x[1]))][1:Top_n]\n",
    "top_models_cleaned <- names(top_mape_val)\n",
    "    \n",
    "top_mape_val\n",
    "seasonal_cleaned_mean    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 1: Seasonally adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_series,col = \"black\")\n",
    "lines(test_data_adj, col = \"blue\")\n",
    "lines(forecast.ets(test_models_adj[[top_models_adj[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_adj[[top_models_adj[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_adj[[top_models_adj[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2: Seasonally adjusted & cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_series_cleaned,col = \"black\")\n",
    "lines(test_data_adj_cleaned, col = \"blue\")\n",
    "lines(forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 3: Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_fit\n",
    "#test_models[[all_fit[1]]]\n",
    "\n",
    "plot(series,col = \"black\")\n",
    "lines(test_data, col = \"blue\")\n",
    "\n",
    "top_models[1]\n",
    "accuracy(test_models[[top_models[1]]])\n",
    "top_models[2]\n",
    "accuracy(test_models[[top_models[2]]])\n",
    "top_models[3]\n",
    "accuracy(test_models[[top_models[3]]])\n",
    "\n",
    "\n",
    "lines(forecast.ets(test_models[[top_models[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models[[top_models[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models[[top_models[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 4: Cleaned original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12))\n",
    "\n",
    "accuracy(test_models_cleaned[[top_models_cleaned[1]]])\n",
    "accuracy(test_models_cleaned[[top_models_cleaned[2]]])\n",
    "accuracy(test_models_cleaned[[top_models_cleaned[3]]])\n",
    "\n",
    "\n",
    "plot(series.cleaned,col = \"black\")\n",
    "lines(test_data_cleaned, col = \"blue\")\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data(cleaned)\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting back the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1: Seasonally adjusted data (To bring back the original data, seasonal component and the Bias value is added back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Case 1: Seasonally adjusted data\")\n",
    "#Adding the bias value which was added to overcome the negative values\n",
    "ES_series_bias <- ES_series - bias_value\n",
    "test_series_bias <- test_data_adj - bias_value\n",
    "forecast1_bias <- forecast.ets(test_models_adj[[top_models_adj[1]]],h=12)$mean - bias_value\n",
    "forecast2_bias <- forecast.ets(test_models_adj[[top_models_adj[2]]],h=12)$mean - bias_value\n",
    "forecast3_bias <- forecast.ets(test_models_adj[[top_models_adj[3]]],h=12)$mean - bias_value\n",
    "\n",
    "#Adding back the seasonal value from stl decomposition\n",
    "ES_value_adj <- ES_series_bias + seasonal\n",
    "test_series_adj <- test_series_bias + seasonal\n",
    "\n",
    "#Adding back the mean seasonal component to the forecasted data\n",
    "forecast1_adj <- forecast1_bias + seasonal_mean\n",
    "forecast2_adj <- forecast2_bias + seasonal_mean\n",
    "forecast3_adj <- forecast3_bias + seasonal_mean\n",
    "\n",
    "#Calculating the accuracy of the training data\n",
    "accuracy(test_models_adj[[top_models_adj[1]]])\n",
    "accuracy(test_models_adj[[top_models_adj[2]]])\n",
    "accuracy(test_models_adj[[top_models_adj[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking the MAPE values with original data\n",
    "print(paste0(\"Top model: \", top_models_adj[1]))\n",
    "accuracy(forecast1_adj,test_series_adj)\n",
    "print(paste0(\"Top model: \", top_models_adj[2]))\n",
    "accuracy(forecast2_adj,test_series_adj)\n",
    "print(paste0(\"Top model: \", top_models_adj[3]))\n",
    "accuracy(forecast3_adj,test_series_adj)\n",
    "\n",
    "#accuracy(test_data, forecast.ets(test_models[[top_models[3]]],h=12)$mean )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Seasonally adjusted & cleaned data (To bring back the original data, seasonal component and the Bias value is added back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Case 2: Seasonally adjusted & cleaned data\")\n",
    "#Adding the bias value which was added to overcome the negative values\n",
    "\n",
    "\n",
    "ES_series_bias_cleaned <- ES_series_cleaned - bias_value_cleaned\n",
    "test_series_bias_cleaned <- test_data_adj_cleaned - bias_value_cleaned\n",
    "\n",
    "\n",
    "forecast1_bias <- forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[1]]],h=12)$mean - bias_value_cleaned\n",
    "forecast2_bias <- forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[2]]],h=12)$mean - bias_value_cleaned\n",
    "forecast3_bias <- forecast.ets(test_models_adj_cleaned[[top_models_adj_cleaned[3]]],h=12)$mean - bias_value_cleaned\n",
    "\n",
    "#Adding back the seasonal value from stl decomposition\n",
    "ES_value_adj_cleaned <- ES_series_bias_cleaned + seasonal_cleaned\n",
    "test_series_adj_cleaned <- test_series_bias_cleaned + seasonal_cleaned\n",
    "\n",
    "#Adding back the mean seasonal component to the forecasted data\n",
    "forecast1_adj_cleaned <- forecast1_bias + seasonal_cleaned_mean\n",
    "forecast2_adj_cleaned <- forecast2_bias + seasonal_cleaned_mean\n",
    "forecast3_adj_cleaned <- forecast3_bias + seasonal_cleaned_mean\n",
    "\n",
    "#Calculating the accuracy of the training data\n",
    "accuracy(test_models_adj_cleaned[[top_models_adj_cleaned[1]]])\n",
    "accuracy(test_models_adj_cleaned[[top_models_adj_cleaned[2]]])\n",
    "accuracy(test_models_adj_cleaned[[top_models_adj_cleaned[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking the MAPE values with original data\n",
    "print(paste0(\"Top model: \", top_models_adj_cleaned[1]))\n",
    "accuracy(forecast1_adj_cleaned,test_series_adj_cleaned)\n",
    "print(paste0(\"Top model: \", top_models_adj_cleaned[2]))\n",
    "accuracy(forecast2_adj_cleaned,test_series_adj_cleaned)\n",
    "print(paste0(\"Top model: \", top_models_adj_cleaned[3]))\n",
    "accuracy(forecast3_adj_cleaned,test_series_adj_cleaned)\n",
    "\n",
    "top_models\n",
    "\n",
    "#accuracy(forecast.ets(test_models[[top_models[1]]],h=12)$mean, test_data)\n",
    "\n",
    "#accuracy(test_data, forecast.ets(test_models[[top_models[3]]],h=12)$mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ljung Box test - One of the checks to perform stationarity of TS data\n",
    "# A small function\n",
    "residual_analyis <- function(model_name){\n",
    "    print(model_name)\n",
    "    print(Box.test(test_models[[model_name]]$residuals, lag = 20, type = \"Ljung-Box\"))\n",
    "    #p_value <- Box.test(test_models[[model_name]]$residuals, lag = 20, type = \"Ljung-Box\")\n",
    "    Acf(test_models[[model_name]]$residuals, main = model_name)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 1: Seasonally adjusted models\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models_adj[1]) #Top model\n",
    "residual_analyis(top_models_adj[2]) #Second best model\n",
    "residual_analyis(top_models_adj[3]) #Third best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 2 - Seasonally adjusted cleaned models\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models_adj_cleaned[1]) #Top model\n",
    "residual_analyis(top_models_adj_cleaned[2]) #Second best model\n",
    "residual_analyis(top_models_adj_cleaned[3]) #Third best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 3 - Models on original data\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models[1]) #Top model\n",
    "residual_analyis(top_models[2]) #Second best model\n",
    "residual_analyis(top_models[3]) #Third best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Case 4 - Models on original data\n",
    "#Residual Analysis for top three models\n",
    "residual_analyis(top_models_cleaned[1]) #Top model\n",
    "residual_analyis(top_models_cleaned[2]) #Second best model\n",
    "residual_analyis(top_models_cleaned[3]) #Third best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual output: Except the best model of original dataset which shows unusually high autocorrelation among the residuals, all the other models' residuals show no significant autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output:\n",
    "\n",
    "#### Analysing each case and figuring out the most suitable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Model for seasonally adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_value_adj,col = \"black\", ylab = \"No of complaints\", \n",
    "                 main = \"Model with seasonal adjustment\")\n",
    "\n",
    "lines(test_series_adj, col = \"blue\") #Original test data\n",
    "\n",
    "\n",
    "accuracy(forecast1_adj,test_series_adj)\n",
    "accuracy(forecast2_adj,test_series_adj)\n",
    "accuracy(forecast3_adj,test_series_adj)\n",
    "\n",
    "\n",
    "lines(test_series_bias + seasonal_mean, col = \"brown\", lty =2) #Deseasonlised data with average seasonal component applied\n",
    "lines(forecast1_adj, col = \"red\") #Top model\n",
    "lines(forecast2_adj, col = \"green\") #Top second model\n",
    "lines(forecast3_adj, col = \"yellow\") #Top third model\n",
    "\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\",\"test data with seasonal mean\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: MAPE values are not significantly less, yet from the plot it is seen that the predicted values suffer from a constant bias, which if rectified would form a great forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Model for seasonally adjusted and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(ES_value_adj_cleaned,col = \"black\", ylab = \"No of complaints\",\n",
    "                 main = \"Model with seasonal adjustment and cleaning\") \n",
    "lines(test_series_adj_cleaned, col = \"blue\") #Original test data\n",
    "\n",
    "\n",
    "\n",
    "accuracy(forecast1_adj_cleaned,test_series_adj_cleaned)\n",
    "accuracy(forecast2_adj_cleaned,test_series_adj_cleaned)\n",
    "accuracy(forecast3_adj_cleaned,test_series_adj_cleaned)\n",
    "\n",
    "\n",
    "lines(test_series_bias_cleaned + seasonal_cleaned_mean, col = \"brown\", lty =2) #Deseasonlised data with average seasonal component applied\n",
    "lines(forecast1_adj_cleaned, col = \"red\") #Top model\n",
    "lines(forecast2_adj_cleaned, col = \"green\") #Top second model\n",
    "lines(forecast3_adj_cleaned, col = \"yellow\") #Top third model\n",
    "\n",
    "\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\",\"test data with seasonal mean\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Since the cleaned data has no much difference from the original data, the results are comparable and almost the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: Model for the original data as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(series,col = \"black\", ylab = \"No of complaints\",\n",
    "                 main = \"Model with original data\") \n",
    "lines(test_data, col = \"blue\") #Originayl test data\n",
    "\n",
    "\n",
    "accuracy(forecast.ets(test_models[[top_models[1]]],h=12)$mean,test_data)\n",
    "accuracy(forecast.ets(test_models[[top_models[2]]],h=12)$mean,test_data)\n",
    "accuracy(forecast.ets(test_models[[top_models[3]]],h=12)$mean,test_data)\n",
    "\n",
    "\n",
    "lines(forecast.ets(test_models[[top_models[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models[[top_models[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models[[top_models[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\", lty=1,col = c(\"blue\",\"red\",\"green\",\"yellow\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\"))\n",
    "\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly\n",
    "\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data\", \"Best model\", \"Second best\", \"Third best\",\"test data with seasonal mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Even though the MAPE values are lesser than the seasonally adjusted models, the models here doesn't depict the month on month variations (seasonality) properly except the top model gives not so bad predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4: Model for original data which is cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(series.cleaned,col = \"black\", main = \"Model with cleaned data\")\n",
    "lines(test_data_cleaned, col = \"blue\")\n",
    "\n",
    "accuracy(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12)$mean,test_data_cleaned)\n",
    "accuracy(forecast.ets(test_models_cleaned[[top_models_cleaned[2]]],h=12)$mean,test_data_cleaned)\n",
    "accuracy(forecast.ets(test_models_cleaned[[top_models_cleaned[3]]],h=12)$mean,test_data_cleaned)\n",
    "\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[1]]],h=12)$mean, col = \"red\") #Top model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[2]]],h=12)$mean, col = \"green\") #Top second model\n",
    "lines(forecast.ets(test_models_cleaned[[top_models_cleaned[3]]],h=12)$mean, col = \"yellow\") #Top third model\n",
    "legend(\"topleft\",lty=c(1,1,1,1,2),col = c(\"blue\",\"red\",\"green\",\"yellow\",\"brown\"),\n",
    "                       c(\"Test data(cleaned)\", \"Best model\", \"Second best\", \"Third best\",\"Actual test data\"))\n",
    "#Observation: Unusual peak at December'15. To check if it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: The models perform worse that the models created for original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: Analysing all the models, it appears that the models for seasonally adjusted data gives better and reliable predictions eventhough it suffers a constant bias. It is also very clear that models with lesser MAPE values may not always be the right fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
